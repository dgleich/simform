



Tiny test
---------

    make setup_database variable=TEMP dir=hdfs://icme-hadoop1.localdomain/user/jatempl/random_media/run? outdir=hdfs://icme-hadoop1.localdomain/user/dgleich/rm-sisc/dbtest name=dbtest

   mv dbtest dbtest.dgleich

Add numParams?=64
    numExodusfiles?=16
    timesteps?=tstepstest.txt
    mr_seq2mseq2_hadoop.py -> mr_seq2mseq5_hadoop.py

     (5 is a special version to parse the parameter numbers correctly for this
one)

    make -f dbtest.dgleich preprocess


Use this timesteps file

cat tstepstest.txt 
1250.0
1650.0
2000.0

Fix up the input list

    bash make_db_test_input.sh

    hadoop fs -rm
hdfs://icme-hadoop1.localdomain/user/dgleich/rm-sisc/dbtest/input.txt
    hadoop fs -put inputtest.txt
hdfs://icme-hadoop1.localdomain/user/dgleich/rm-sisc/dbtest/input.txt 

    make -f dbtest.dgleich convert
    make -f dbtest.dgleich seq2mseq2

Store the matrix for processing myself

    cd model
    python dump_mseq2.py -hadoop /usr/lib/hadoop -mat rm-sisc/dbtest/data.mseq2
    mkdir ../../../experiments/dbtest
    hadoop fs -text /user/dgleich/rm-sisc/dbtest/data.mtxt/part-00000.deflate > ../../../experiments/dbtest/data.mtxt
    cd ..
    cp tstepstest.txt ../../experiments/dbtest/tsteps.txt
    cd 

On my desktop

    # work in the ssh shared directory
    cd ~/remote/icme-hadoop1/simform-sisc/experiments/dbtest
    convert_dbtest
    
Then we can use

    split_test2.m to generate true errors    
    
That will save dbtest.mat into ~/scratch we can use it to verify the SVD

    make -f dbtest.dgleich model # compute the full SVD
    make -f dbtest.dgleich train # compute an SVD on a training subset
    
Let's do some prediction! The code paul wrote does:
python compute_interp_weights.py Vtfile Sigmafile designpoints interppoints > dbtest-weights.txt

dbtest parameter set    
1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61
trainset design
1 17 33 49
testset design
9 25 41     

Let's make sure it's right

    cat dbtest-trainset-design.txt    
    cat dbtest-testset-design.txt

Now let's use Paul's script to compute things!

    python compute_interp_weights.py model/svd-test-train/Vt.txt.out \
      model/svd-test-train/Sigma.txt.out \
      dbtest-trainset-design.txt  dbtest-testset-design.txt R 4 > dbtest-weights.txt
      
      

python mr_predict2_hadoop.py \
  hdfs://icme-hadoop1.localdomain/user/dgleich/rm-sisc/dbtest/train_3/p* \
  -r hadoop --no-output -o rm-sisc/dbtest/predict \
  --weights=dbtest-weights.txt --file dbtest-weights.txt \
  --subset=9,25,41



python mr_error_hadoop.py \
hdfs://icme-hadoop1.localdomain/user/dgleich/rm-sisc/dbtest/data.seq/random_media/random_media*.seq \
hdfs://icme-hadoop1.localdomain/user/dgleich/rm-sisc/dbtest/predict/p* \
-r hadoop --no-output -o rm-sisc/dbtest/error --numParas 64  --variable TEMP \
--subset=9,25,41
  
Summary of notes while working on this. The initial SVD was wrong due to the
'uotp' bug in the svd code. So I fixed that. Also 

I validated this by making sure the error was the same against the ones 
computed in Matlab.

    # make sure it's a REAL tab after the 9 (in linux, <ctrl-v> <TAB>)
    dumbo cat rm-sisc/dbtest/error/part-* -hadoop /usr/lib/hadoop | \
        grep "9 " | cut -f 4 

One of the key problems was that the first elements of the predicted
scores was not 1000, which it's fixed to in all of the simulations, so this
indicates a bug.

    dumbo cat rm-sisc/dbtest/predict/part-00007 -hadoop /usr/lib/hadoop | less
    
---

Alright, it turns out it was too slow to compute all the predictions independently.

We integrated them all    
    
    cd model
    python run_full_tsqr_cv.py --parameter-file=../dbtest-params.txt \
        --train-subset=0,4,8,12 --test-subset=2,6,10 \
        --replication=1 --javamem=7g \
        --input=rm-sisc/dbtest/data.mseq2/ \
        --hadoop=/usr/lib/hadoop \
        --local_output=svd-test-train \
        --output=rm-sisc/dbtest/traincv 
        
        
    Individual commands
    
    dumbo start full1.py -hadoop /usr/lib/hadoop -mat rm-sisc/dbtest/data.mseq2/ \
     -output rm-sisc/dbtest/traincv_1 -subset 0,4,8,12 -saveA 1 \
     -libjar feathers.jar  -jobconf dfs.replication=1 \
     -jobconf mapred.map.max.attempts=10 -jobconf mapred.task.timeout=1200000
     
    dumbo start full2.py -hadoop /usr/lib/hadoop -mat rm-sisc/dbtest/traincv_1/R_* -output rm-sisc/dbtest/traincv_2 -svd 3 -libjar feathers.jar  -jobconf mapred.map.max.attempts=10 -jobconf mapred.task.timeout=1200000
    
    hadoop fs -copyToLocal rm-sisc/dbtest/traincv_2/Q2/part-00000 svd-test-train/Q2.txt
    python /home/dgleich/simform-sisc/simform/src/model/hyy-python-hadoop/examples/SequenceFileReader.py svd-test-train/Q2.txt > svd-test-train/Q2.txt.out

    hadoop fs -copyToLocal rm-sisc/dbtest/traincv_2/U/part-00000 svd-test-train/U.txt
    python /home/dgleich/simform-sisc/simform/src/model/hyy-python-hadoop/examples/SequenceFileReader.py svd-test-train/U.txt > svd-test-train/U.txt.out
    
    hadoop fs -copyToLocal rm-sisc/dbtest/traincv_2/Sigma/part-00000 svd-test-train/Sigma.txt
    python /home/dgleich/simform-sisc/simform/src/model/hyy-python-hadoop/examples/SequenceFileReader.py svd-test-train/Sigma.txt > svd-test-train/Sigma.txt.out
    
    hadoop fs -copyToLocal rm-sisc/dbtest/traincv_2/Sigma/part-00000 svd-test-train/Vt.txt
    python /home/dgleich/simform-sisc/simform/src/model/hyy-python-hadoop/examples/SequenceFileReader.py svd-test-train/Vt.txt > svd-test-train/Vt.txt.out
    
    dumbo start full3cv.py -hadoop /usr/lib/hadoop -mat rm-sisc/dbtest/traincv_1/Q_* \
        -output rm-sisc/dbtest/traincv_3 -q2path svd-test-train/Q2.txt.out \
        -libjar feathers.jar \
        -subset 0,4,8,12 -test_subset 2,6,10 \
        -ppath ../dbtest-params.txt -upath svd-test-train/U.txt.out \
        -sigmapath svd-test-train/Sigma.txt.out -vtpath svd-test-train/Vt.txt.out  \
        -jobconf dfs.replication=1 -jobconf mapred.map.max.attempts=10 \
        -jobconf mapred.task.timeout=1200000 \
        -jobconf mapred.child.java.opts="-Xmx7g"
    
    dumbo cat rm-sisc/dbtest/traincv_3/part-* -hadoop /usr/lib/hadoop > errs.txt
    
    cat errs.txt | python parse_errors.py
        
